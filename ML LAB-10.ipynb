{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84c1b189-9dc0-49ae-ae43-62c0690e4e0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/mnt/data/ML_DATASET_HENRY/Training\\\\glioma'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Process training and testing images\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m class_name \u001b[38;5;129;01min\u001b[39;00m classes:\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m image_name \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(train_dir, class_name)):\n\u001b[0;32m     25\u001b[0m         image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(train_dir, class_name, image_name)\n\u001b[0;32m     26\u001b[0m         X_train\u001b[38;5;241m.\u001b[39mappend(extract_image_features(image_path))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/mnt/data/ML_DATASET_HENRY/Training\\\\glioma'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Function to extract image width and height features\n",
    "def extract_image_features(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((150, 150))  # Resize to a fixed size\n",
    "    width, height = img.size\n",
    "    return width, height\n",
    "\n",
    "# Directory paths and classes\n",
    "train_dir = '/mnt/data/ML_DATASET_HENRY/Training'\n",
    "test_dir = '/mnt/data/ML_DATASET_HENRY/Testing'\n",
    "classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "\n",
    "# Initialize lists to hold features and labels\n",
    "X_train, X_test = [], []\n",
    "\n",
    "# Process training and testing images\n",
    "for class_name in classes:\n",
    "    for image_name in os.listdir(os.path.join(train_dir, class_name)):\n",
    "        image_path = os.path.join(train_dir, class_name, image_name)\n",
    "        X_train.append(extract_image_features(image_path))\n",
    "\n",
    "    for image_name in os.listdir(os.path.join(test_dir, class_name)):\n",
    "        image_path = os.path.join(test_dir, class_name, image_name)\n",
    "        X_test.append(extract_image_features(image_path))\n",
    "\n",
    "# Convert to NumPy arrays and merge train/test sets\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "X_combined = np.vstack((X_train, X_test))\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_combined_scaled = scaler.fit_transform(X_combined)\n",
    "\n",
    "# Apply k-means clustering with k=5\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans.fit(X_combined_scaled)\n",
    "\n",
    "# Output cluster centers and labels\n",
    "print(f\"Cluster Centers: \\n{kmeans.cluster_centers_}\")\n",
    "print(f\"Cluster Labels: {kmeans.labels_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "123612e2-7c98-4a84-a36f-aefea551efa5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_combined_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m k_range:\n\u001b[0;32m      9\u001b[0m     kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39mk, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m     kmeans\u001b[38;5;241m.\u001b[39mfit(X_combined_scaled)\n\u001b[0;32m     11\u001b[0m     inertia\u001b[38;5;241m.\u001b[39mappend(kmeans\u001b[38;5;241m.\u001b[39minertia_)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Plot the elbow curve\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_combined_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Elbow method to find the optimal k\n",
    "inertia = []\n",
    "k_range = range(1, 31)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_combined_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.plot(k_range, inertia, marker='o')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6bd1005-c607-4c13-b0e0-f68a6cd9d8ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_combined_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AgglomerativeClustering\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Perform agglomerative clustering\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m linked \u001b[38;5;241m=\u001b[39m linkage(X_combined_scaled, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mward\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Plot the dendrogram\u001b[39;00m\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m7\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_combined_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Perform agglomerative clustering\n",
    "linked = linkage(X_combined_scaled, method='ward')\n",
    "\n",
    "# Plot the dendrogram\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(linked, orientation='top', distance_sort='descending', show_leaf_counts=True)\n",
    "plt.title('Dendrogram for Hierarchical Clustering')\n",
    "plt.show()\n",
    "\n",
    "# Applying Agglomerative Clustering\n",
    "agg_clustering = AgglomerativeClustering(n_clusters=5)\n",
    "agg_clustering.fit(X_combined_scaled)\n",
    "\n",
    "# Output the cluster labels\n",
    "print(f\"Agglomerative Clustering Labels: {agg_clustering.labels_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b37db37b-cbfa-434b-9639-783c4a8528ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_combined_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Sequential Forward Selection (SFS)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m sfs \u001b[38;5;241m=\u001b[39m SequentialFeatureSelector(log_reg, n_features_to_select\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m sfs\u001b[38;5;241m.\u001b[39mfit(X_combined_scaled, kmeans\u001b[38;5;241m.\u001b[39mlabels_)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Display the selected features\u001b[39;00m\n\u001b[0;32m     12\u001b[0m selected_features \u001b[38;5;241m=\u001b[39m sfs\u001b[38;5;241m.\u001b[39mget_support()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_combined_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic regression as the base model for feature selection\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Sequential Forward Selection (SFS)\n",
    "sfs = SequentialFeatureSelector(log_reg, n_features_to_select=1, direction='forward')\n",
    "sfs.fit(X_combined_scaled, kmeans.labels_)\n",
    "\n",
    "# Display the selected features\n",
    "selected_features = sfs.get_support()\n",
    "print(f\"Selected features: {selected_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b28ba4aa-44f2-4f90-9aa5-e2167861820e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_combined_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Apply PCA\u001b[39;00m\n\u001b[0;32m      7\u001b[0m pca \u001b[38;5;241m=\u001b[39m PCA()\n\u001b[1;32m----> 8\u001b[0m X_pca \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mfit_transform(X_combined_scaled)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Plot the explained variance ratio\u001b[39;00m\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39mcumsum(pca\u001b[38;5;241m.\u001b[39mexplained_variance_ratio_))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_combined_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_combined_scaled)\n",
    "\n",
    "# Plot the explained variance ratio\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('PCA - Explained Variance vs. Number of Components')\n",
    "plt.axhline(y=0.95, color='r', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "# Find the number of components that capture 95% variance\n",
    "n_components = np.argmax(np.cumsum(pca.explained_variance_ratio_) >= 0.95) + 1\n",
    "print(f\"Number of components to capture 95% variance: {n_components}\")\n",
    "\n",
    "# Transform the data with the top K principal components\n",
    "pca = PCA(n_components=n_components)\n",
    "X_pca_transformed = pca.fit_transform(X_combined_scaled)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_pca, X_test_pca, y_train, y_test = train_test_split(X_pca_transformed, kmeans.labels_, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train logistic regression on PCA-transformed data\n",
    "log_reg_pca = LogisticRegression(max_iter=1000)\n",
    "log_reg_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict and calculate accuracy\n",
    "y_pred_pca = log_reg_pca.predict(X_test_pca)\n",
    "accuracy_pca = accuracy_score(y_test, y_pred_pca)\n",
    "print(f\"Accuracy with PCA-transformed data: {accuracy_pca:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa990bf-b22c-4986-ab9f-906ac2c77ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
